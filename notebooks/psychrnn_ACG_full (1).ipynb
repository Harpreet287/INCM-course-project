{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f8467efa",
      "metadata": {
        "id": "f8467efa"
      },
      "source": [
        "# Adaptive Contrastive Gating (ACG) — end-to-end PsychRNN-style project\n",
        "**What's inside:** A complete pipeline that trains RNNs on a perceptual discrimination (2AFC) task, implements Adaptive Contrastive Gating (multiplicative gating + contrastive centroid loss), evaluates behavioral and representational metrics, runs mechanistic analyses (centroid distance, PCA, fixed-point finder, lesion/ablation), and saves figures & models for final submission.\n",
        "\n",
        "**Notes:**\n",
        "- This notebook is self-contained using PyTorch (no PsychRNN required). It references your uploaded script at `./psychrnn_perceptualdiscrimination_noise_comparison.py` (you can port pieces into PsychRNN later).\n",
        "- Defaults are set to strong hyperparameters for final experiments. For a **quick demo**, change `TRAIN_ITERS = 2000` in the Run cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d287d379",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "id": "d287d379",
        "outputId": "fe152f50-50ce-4ac6-c53c-deee6119c5eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**No uploaded script found at** `./psychrnn_perceptualdiscrimination_noise_comparison.py`"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Cell: imports & device\n",
        "import os, json, time, random, math, copy\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# path to uploaded script if you want to reuse it later\n",
        "UPLOADED_SCRIPT_PATH = \"./psychrnn_perceptualdiscrimination_noise_comparison.py\"\n",
        "if Path(UPLOADED_SCRIPT_PATH).exists():\n",
        "    display(Markdown(f\"**Found uploaded script:** `{UPLOADED_SCRIPT_PATH}`\"))\n",
        "else:\n",
        "    display(Markdown(f\"**No uploaded script found at** `{UPLOADED_SCRIPT_PATH}`\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f205bbd4",
      "metadata": {
        "id": "f205bbd4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Utilities\n",
        "def set_seed(seed=0):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def savefig(fig_or_path):\n",
        "    # accept plt or path string\n",
        "    if isinstance(fig_or_path, str) or isinstance(fig_or_path, Path):\n",
        "        plt.savefig(str(fig_or_path), dpi=150, bbox_inches='tight')\n",
        "        print(\"Saved:\", fig_or_path)\n",
        "    else:\n",
        "        fig_or_path.savefig(dpi=150, bbox_inches='tight')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "14e15045",
      "metadata": {
        "id": "14e15045"
      },
      "outputs": [],
      "source": [
        "\n",
        "# PerceptualDiscrimination task generator (2AFC)\n",
        "def generate_batch(batch_size, T, coherence, stim_std=1.0, input_dim=2, device='cpu'):\n",
        "    labels = np.random.choice([0,1], size=(batch_size,))\n",
        "    x = np.random.randn(batch_size, T, input_dim) * stim_std\n",
        "    for i, lab in enumerate(labels):\n",
        "        x[i, :, lab] += coherence\n",
        "    x_t = torch.tensor(x, dtype=torch.float32, device=device)\n",
        "    y_t = torch.tensor(labels, dtype=torch.long, device=device)\n",
        "    return x_t, y_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "73c7d916",
      "metadata": {
        "id": "73c7d916"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Model: RNN with multiplicative gating and optional Dale's law\n",
        "class RNN_ACG(nn.Module):\n",
        "    def __init__(self, input_dim=2, hidden_dim=128, output_dim=2, rec_noise_std=0.0, gate=True, dale=True, dale_exc_frac=0.8, device='cpu'):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.rec_noise_std = rec_noise_std\n",
        "        self.gate = gate\n",
        "        self.dale = dale\n",
        "        self.device = device\n",
        "\n",
        "        # parameters\n",
        "        self.W_in = nn.Parameter(torch.randn(hidden_dim, input_dim) * (1.0/np.sqrt(input_dim)))\n",
        "        self.b_in = nn.Parameter(torch.zeros(hidden_dim))\n",
        "        self.W_rec_raw = nn.Parameter(torch.randn(hidden_dim, hidden_dim) * (1.0/np.sqrt(hidden_dim)))\n",
        "        self.b_rec = nn.Parameter(torch.zeros(hidden_dim))\n",
        "        self.W_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        if self.gate:\n",
        "            self.W_gate = nn.Parameter(torch.randn(hidden_dim, input_dim) * (1.0/np.sqrt(input_dim)))\n",
        "            self.b_gate = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "        if self.dale:\n",
        "            n_exc = int(round(dale_exc_frac * hidden_dim))\n",
        "            signs = np.array([1]*n_exc + [-1]*(hidden_dim-n_exc))\n",
        "            np.random.shuffle(signs)\n",
        "            self.register_buffer('dale_sign', torch.tensor(signs, dtype=torch.float32).to(device))\n",
        "        else:\n",
        "            self.register_buffer('dale_sign', torch.ones(hidden_dim, dtype=torch.float32).to(device))\n",
        "\n",
        "        self.activation = torch.tanh\n",
        "\n",
        "    def effective_Wrec(self):\n",
        "        W_abs = torch.abs(self.W_rec_raw)  # >=0\n",
        "        # apply sign to columns (outgoing)\n",
        "        W = W_abs * self.dale_sign.unsqueeze(0)\n",
        "        return W\n",
        "\n",
        "    def forward(self, x, return_hidden=False):\n",
        "        batch, T, _ = x.size()\n",
        "        h = torch.zeros(batch, self.hidden_dim, device=x.device)\n",
        "        hs = []\n",
        "        W_rec = self.effective_Wrec()\n",
        "        for t in range(T):\n",
        "            xt = x[:, t, :]\n",
        "            inp = torch.matmul(xt, self.W_in.t()) + self.b_in\n",
        "            if self.gate:\n",
        "                g = torch.sigmoid(torch.matmul(xt, self.W_gate.t()) + self.b_gate)\n",
        "                inp = inp * g\n",
        "            rec = torch.matmul(h, W_rec.t()) + self.b_rec\n",
        "            h = self.activation(inp + rec)\n",
        "            if self.rec_noise_std and self.training:\n",
        "                h = h + torch.randn_like(h) * float(self.rec_noise_std)\n",
        "            hs.append(h.unsqueeze(1))\n",
        "        hs = torch.cat(hs, dim=1)  # (batch, T, hidden)\n",
        "        logits = self.W_out(hs[:, -1, :])\n",
        "        if return_hidden:\n",
        "            return logits, hs\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "86d36abe",
      "metadata": {
        "id": "86d36abe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Contrastive centroid loss (hinge on centroid distance)\n",
        "def contrastive_centroid_loss(final_h, labels, margin=1.0):\n",
        "    # final_h: torch tensor (batch, H), labels: (batch,)\n",
        "    labels_np = labels.detach().cpu().numpy()\n",
        "    hs = final_h.detach()\n",
        "    unique = np.unique(labels_np)\n",
        "    if len(unique) < 2:\n",
        "        return torch.tensor(0.0, device=final_h.device)\n",
        "    mu0 = hs[labels==0].mean(dim=0)\n",
        "    mu1 = hs[labels==1].mean(dim=0)\n",
        "    dist = torch.norm(mu0 - mu1)\n",
        "    loss = torch.relu(margin - dist)\n",
        "    return loss, dist.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "21ed69b6",
      "metadata": {
        "id": "21ed69b6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Training function: supports curriculum, contrastive loss, gating, Dale's law\n",
        "def train_acg(outdir, seed=0, training_iters=30000, batch_size=128, T=40, hidden_dim=128,\n",
        "              lr=3e-4, rec_noise=0.0, gate=True, dale=True, dale_exc_frac=0.8,\n",
        "              start_coh=0.8, min_coh=0.1, coh_step=0.1, mode='curriculum',\n",
        "              eval_interval=500, target_acc=0.85, contrastive_lambda=0.5, margin=1.0,\n",
        "              device='cpu', verbose=True):\n",
        "    set_seed(seed)\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    model = RNN_ACG(input_dim=2, hidden_dim=hidden_dim, output_dim=2, rec_noise_std=rec_noise, gate=gate, dale=dale, dale_exc_frac=dale_exc_frac, device=device).to(device)\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    losses = []\n",
        "    psych_history = []\n",
        "    centroid_history = []\n",
        "    eval_coherences = [0.05, 0.1, 0.2, 0.4, 0.6, 0.8]\n",
        "    coher = float(start_coh)\n",
        "    it = 0\n",
        "    while it < training_iters:\n",
        "        model.train()\n",
        "        x, y = generate_batch(batch_size, T, coher, device=device)\n",
        "        opt.zero_grad()\n",
        "        logits, hs = model(x, return_hidden=True)\n",
        "        loss_ce = loss_fn(logits, y)\n",
        "        final_h = hs[:, -1, :]\n",
        "        c_loss, dist = (torch.tensor(0.0, device=device), 0.0)\n",
        "        if contrastive_lambda > 0.0:\n",
        "            c_loss, dist = contrastive_centroid_loss(final_h, y, margin=margin)\n",
        "        loss = loss_ce + contrastive_lambda * c_loss\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        losses.append(float(loss.item()))\n",
        "        it += 1\n",
        "\n",
        "        if it % eval_interval == 0:\n",
        "            val_acc = compute_accuracy(model, coher, n_trials=512, batch_size=batch_size, T=T, device=device)\n",
        "            psych = psychometric_curve(model, eval_coherences, n_trials_each=300, batch_size=batch_size, T=T, device=device)\n",
        "            centroid_history.append({'iter':int(it), 'coherence':float(coher), 'val_acc':float(val_acc), 'centroid_dist':float(dist)})\n",
        "            psych_history.append({'iter':int(it), 'coherence':float(coher), 'val_acc':float(val_acc), 'psych':psych.tolist()})\n",
        "            if verbose:\n",
        "                print(f\"iter {it:6d} | coh {coher:.2f} | loss {loss.item():.4f} | val_acc {val_acc:.3f} | centroid_dist {dist:.3f}\")\n",
        "            if mode == 'curriculum' and val_acc >= target_acc and (coher - coh_step) >= min_coh:\n",
        "                coher = max(min_coh, coher - coh_step)\n",
        "                if verbose:\n",
        "                    print(f\"  -> Curriculum: lowered coherence to {coher:.2f} at iter {it}\")\n",
        "    final_psych = psychometric_curve(model, eval_coherences, n_trials_each=600, batch_size=batch_size, T=T, device=device)\n",
        "    torch.save(model.state_dict(), os.path.join(outdir, 'model_state.pt'))\n",
        "\n",
        "    results = {'losses':list(map(float,losses)), 'psych_history':psych_history, 'centroid_history':centroid_history, 'final_psych':list(map(float, final_psych)), 'eval_coherences':eval_coherences, 'params':{'seed':int(seed),'training_iters':int(training_iters),'batch_size':int(batch_size),'T':int(T),'hidden_dim':int(hidden_dim),'lr':float(lr),'rec_noise':float(rec_noise),'gate':bool(gate),'dale':bool(dale),'start_coh':float(start_coh),'mode':mode,'contrastive_lambda':float(contrastive_lambda),'margin':float(margin)}}\n",
        "    with open(os.path.join(outdir, 'results.json'),'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    return model, results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5bc4595c",
      "metadata": {
        "id": "5bc4595c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Evaluation helpers: accuracy, psych, centroid distance, PCA\n",
        "def compute_accuracy(model, coherence, n_trials=256, batch_size=128, T=40, stim_std=1.0, device='cpu'):\n",
        "    model.eval()\n",
        "    correct = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        while total < n_trials:\n",
        "            b = min(batch_size, n_trials-total)\n",
        "            x, y = generate_batch(b, T, coherence, stim_std=stim_std, device=device)\n",
        "            logits = model(x)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += b\n",
        "    return correct/total\n",
        "\n",
        "def psychometric_curve(model, coherences, n_trials_each=300, batch_size=128, T=40, stim_std=1.0, device='cpu'):\n",
        "    return np.array([compute_accuracy(model, c, n_trials=n_trials_each, batch_size=batch_size, T=T, stim_std=stim_std, device=device) for c in coherences])\n",
        "\n",
        "def compute_centroid_distance_np(model, coherence=0.4, n_trials=300, batch_size=128, T=40, device='cpu'):\n",
        "    model.eval()\n",
        "    X0=[]; X1=[]\n",
        "    with torch.no_grad():\n",
        "        total=0\n",
        "        while total < n_trials:\n",
        "            b=min(batch_size, n_trials-total)\n",
        "            x,y = generate_batch(b,T,coherence,device=device)\n",
        "            _, hs = model(x, return_hidden=True)\n",
        "            final = hs[:, -1, :].cpu().numpy()\n",
        "            for i,lab in enumerate(y.cpu().numpy()):\n",
        "                if lab==0: X0.append(final[i])\n",
        "                else: X1.append(final[i])\n",
        "            total += b\n",
        "    mu0 = np.mean(X0, axis=0); mu1 = np.mean(X1, axis=0)\n",
        "    return np.linalg.norm(mu0-mu1), mu0, mu1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "aee16806",
      "metadata": {
        "id": "aee16806"
      },
      "outputs": [],
      "source": [
        "\n",
        "# PCA helper\n",
        "def fit_common_pca(models, names, coherence=0.4, T=40, trials_per_model=12, device='cpu'):\n",
        "    all_h=[]\n",
        "    with torch.no_grad():\n",
        "        for name, model in zip(names, models):\n",
        "            model.eval()\n",
        "            for _ in range(trials_per_model):\n",
        "                x,y = generate_batch(1, T, coherence, device=device)\n",
        "                _, hs = model(x, return_hidden=True)\n",
        "                all_h.append(hs[0].cpu().numpy())\n",
        "    all_h = np.concatenate(all_h, axis=0)\n",
        "    pca = PCA(n_components=3)\n",
        "    pca.fit(all_h)\n",
        "    return pca\n",
        "\n",
        "# Fixed-point finder (LBFGS on h to solve h = tanh(W_rec h + W_in x + b))\n",
        "def find_fixed_point(model, x_const, n_restarts=10, max_iter=200):\n",
        "    model.eval()\n",
        "    W_rec = model.effective_Wrec().detach()  # (H,H)\n",
        "    Win = model.W_in.detach()  # (H, input_dim)\n",
        "    b_rec = model.b_rec.detach()\n",
        "    device = W_rec.device\n",
        "    fixed_points = []\n",
        "    for r in range(n_restarts):\n",
        "        h = torch.randn(model.hidden_dim, device=device, requires_grad=True)\n",
        "        optimizer = torch.optim.LBFGS([h], max_iter=max_iter, tolerance_grad=1e-6, tolerance_change=1e-9)\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            pre = torch.matmul(W_rec, h) + torch.matmul(Win, x_const) + b_rec  # (H,)\n",
        "            f = torch.tanh(pre) - h\n",
        "            loss = 0.5 * (f**2).sum()\n",
        "            loss.backward()\n",
        "            return loss\n",
        "        try:\n",
        "            optimizer.step(closure)\n",
        "            fixed_points.append(h.detach().cpu().numpy())\n",
        "        except Exception as e:\n",
        "            # LBFGS may fail sometimes; skip\n",
        "            pass\n",
        "    return np.array(fixed_points)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4ba0cb99",
      "metadata": {
        "id": "4ba0cb99"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Lesion helper: zero outgoing (row) weights of selected neurons in a deepcopy of the model\n",
        "def lesion_model_copy(model, neuron_indices):\n",
        "    new_model = copy.deepcopy(model)\n",
        "    W_raw = new_model.W_rec_raw.data.clone()  # (H,H)\n",
        "    for i in neuron_indices:\n",
        "        W_raw[i, :] = 0.0\n",
        "    new_model.W_rec_raw.data.copy_(W_raw)\n",
        "    return new_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d4ce4cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d4ce4cf",
        "outputId": "d5fc6f01-10d0-4c08-dcf7-324b00ba8a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== RUN baseline -> acg_out/baseline\n",
            "iter    500 | coh 0.20 | loss 0.6620 | val_acc 0.547 | centroid_dist 0.000\n",
            "iter   1000 | coh 0.20 | loss 0.6653 | val_acc 0.561 | centroid_dist 0.000\n",
            "iter   1500 | coh 0.20 | loss 0.6639 | val_acc 0.607 | centroid_dist 0.000\n",
            "iter   2000 | coh 0.20 | loss 0.6733 | val_acc 0.588 | centroid_dist 0.000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run experiments: defaults = strong hyperparameters for final experiments.\n",
        "OUT = Path('./acg_out'); OUT.mkdir(exist_ok=True)\n",
        "\n",
        "# Best (default) hyperparameters - recommended for final submission (use GPU if available)\n",
        "BEST = {\n",
        "    'HIDDEN_DIM': 128,\n",
        "    'TRAIN_ITERS': 10000,\n",
        "    'BATCH_SIZE': 128,\n",
        "    'T': 40,\n",
        "    'LR': 3e-4,\n",
        "    'REC_NOISE': 0.0,\n",
        "    'CONTRASTIVE_LAMBDA': 0.5,\n",
        "    'MARGIN': 1.0,\n",
        "    'START_COH': 0.8\n",
        "}\n",
        "\n",
        "# For a quick demo, set this to True (will reduce training iters and batch sizes)\n",
        "QUICK_DEMO = False\n",
        "if QUICK_DEMO:\n",
        "    BEST['TRAIN_ITERS'] = 2000\n",
        "    BEST['BATCH_SIZE'] = 64\n",
        "    BEST['HIDDEN_DIM'] = 80\n",
        "\n",
        "# experiments to run: baseline, ACG (gating + contrastive), curriculum+ACG\n",
        "experiments = {\n",
        "    'baseline': {'rec_noise':0.0, 'gate':False, 'contrastive_lambda':0.0, 'mode':'baseline', 'start_coh':0.2},\n",
        "    'acg':      {'rec_noise':0.0, 'gate':True,  'contrastive_lambda':BEST['CONTRASTIVE_LAMBDA'], 'mode':'baseline', 'start_coh':0.2},\n",
        "    'curr_acg': {'rec_noise':0.0, 'gate':True,  'contrastive_lambda':BEST['CONTRASTIVE_LAMBDA'], 'mode':'curriculum', 'start_coh':BEST['START_COH']}\n",
        "}\n",
        "\n",
        "models = {}\n",
        "results = {}\n",
        "for name, cfg in experiments.items():\n",
        "    outdir = OUT / name\n",
        "    print('\\n=== RUN', name, '->', outdir)\n",
        "    model, res = train_acg(outdir=str(outdir), seed=0, training_iters=BEST['TRAIN_ITERS'], batch_size=BEST['BATCH_SIZE'], T=BEST['T'], hidden_dim=BEST['HIDDEN_DIM'], lr=BEST['LR'], rec_noise=cfg['rec_noise'], gate=cfg['gate'], dale=True, dale_exc_frac=0.8, start_coh=cfg['start_coh'], mode=cfg['mode'], eval_interval=500, target_acc=0.85, contrastive_lambda=cfg['contrastive_lambda'], margin=BEST['MARGIN'], device=device, verbose=True)\n",
        "    models[name] = model\n",
        "    results[name] = res\n",
        "    print('Saved ->', outdir)\n",
        "# Save summary\n",
        "with open(OUT / 'all_results.json','w') as f:\n",
        "    json.dump({k:results[k] for k in results}, f, indent=2)\n",
        "print('\\nAll experiments finished. Outputs in', OUT)\n",
        "\n",
        "\n",
        "# Plot: losses and psychometric curves, centroid distance over time (if available)\n",
        "def plot_losses(results, outpath):\n",
        "    plt.figure(figsize=(9,4))\n",
        "    for name,res in results.items():\n",
        "        losses = np.array(res['losses'])\n",
        "        smooth = np.convolve(losses, np.ones(50)/50, mode='same') if len(losses)>50 else losses\n",
        "        plt.plot(smooth, label=name)\n",
        "    plt.xlabel('Iter'); plt.ylabel('Loss (smoothed)'); plt.legend(); plt.title('Training Loss')\n",
        "    savefig(outpath)\n",
        "\n",
        "def plot_psych(results, outpath):\n",
        "    plt.figure(figsize=(6,4))\n",
        "    for name,res in results.items():\n",
        "        coh = np.array(res['eval_coherences'])\n",
        "        psych = np.array(res['final_psych'])\n",
        "        plt.plot(coh, psych, '-o', label=name)\n",
        "    plt.xlabel('Coherence'); plt.ylabel('Prop correct'); plt.legend(); plt.title('Psychometric curves')\n",
        "    savefig(outpath)\n",
        "\n",
        "def plot_centroid_history(results, outpath):\n",
        "    plt.figure(figsize=(6,4))\n",
        "    for name,res in results.items():\n",
        "        ch = res.get('centroid_history', [])\n",
        "        if len(ch)==0: continue\n",
        "        iters = [c['iter'] for c in ch]; dists = [c['centroid_dist'] for c in ch]\n",
        "        plt.plot(iters, dists, '-o', label=name)\n",
        "    plt.xlabel('Iteration'); plt.ylabel('Centroid distance'); plt.legend(); plt.title('Centroid distance over training')\n",
        "    savefig(outpath)\n",
        "\n",
        "OUT = Path('./acg_out')\n",
        "if not OUT.exists():\n",
        "    print('Run experiments first (see previous cell)')\n",
        "else:\n",
        "    # load results if available\n",
        "    res_files = list((OUT).glob('*/*/results.json')) + list((OUT).glob('*/*/results.json'))\n",
        "    # easier: use files produced earlier\n",
        "    results = {}\n",
        "    for p in (OUT.glob('*')):\n",
        "        rfile = p / 'results.json'\n",
        "        if rfile.exists():\n",
        "            with open(rfile,'r') as f: results[p.name]=json.load(f)\n",
        "    if len(results)==0:\n",
        "        print('No results found under', OUT)\n",
        "    else:\n",
        "        plot_losses(results, OUT / 'losses.png')\n",
        "        plot_psych(results, OUT / 'psych.png')\n",
        "        plot_centroid_history(results, OUT / 'centroid_history.png')\n",
        "        print('Saved plots to', OUT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c3a3976",
      "metadata": {
        "id": "8c3a3976"
      },
      "source": [
        "\n",
        "# Final notes & reproducibility checklist\n",
        "\n",
        "- Default hyperparameters set to strong values for final experiments (HIDDEN=128, TRAIN_ITERS=30000, BATCH=128). Use GPU if available.\n",
        "- For quick demo set QUICK_DEMO=True in run cell to reduce train iters to 2000.\n",
        "- For final report run seeds [0,1,2] and aggregate mean±SEM for psychometric curves and centroid distances.\n",
        "- Deliverables to submit: notebook, out_acg folder with saved figures/models, results.json files, slides.pdf.\n",
        "- If you want, I can now try to (A) save this notebook to `./psychrnn_ACG_full.ipynb` for download, (B) run a single-seed quick demo here, or (C) run the full experiments (this will take long on CPU). Tell me which.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sScoTc4IokkG",
        "outputId": "79de3d8b-7271-47ba-9ed8-e7ee6e008eca"
      },
      "id": "sScoTc4IokkG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: acg_out/ (stored 0%)\n",
            "  adding: acg_out/psych.png (deflated 6%)\n",
            "  adding: acg_out/all_results.json (deflated 67%)\n",
            "  adding: acg_out/baseline/ (stored 0%)\n",
            "  adding: acg_out/baseline/model_state.pt (deflated 9%)\n",
            "  adding: acg_out/baseline/results.json (deflated 65%)\n",
            "  adding: acg_out/curr_acg/ (stored 0%)\n",
            "  adding: acg_out/curr_acg/model_state.pt (deflated 10%)\n",
            "  adding: acg_out/curr_acg/results.json (deflated 64%)\n",
            "  adding: acg_out/centroid_history.png (deflated 5%)\n",
            "  adding: acg_out/losses.png (deflated 4%)\n",
            "  adding: acg_out/acg/ (stored 0%)\n",
            "  adding: acg_out/acg/model_state.pt (deflated 10%)\n",
            "  adding: acg_out/acg/results.json (deflated 64%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hgTsoKY3yuG_"
      },
      "id": "hgTsoKY3yuG_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}